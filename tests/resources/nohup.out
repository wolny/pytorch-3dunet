2022-05-17 01:01:52,324 [MainThread] INFO ConfigLoader - Using 'cuda:0' device
2022-05-17 01:01:52,324 [MainThread] INFO TrainingSetup - {'manual_seed': 0, 'model': {'name': 'UNet3D', 'in_channels': 3, 'out_channels': 2, 'layer_order': 'gcr', 'f_maps': 16, 'num_groups': 4, 'final_sigmoid': False, 'is_segmentation': True}, 'trainer': {'checkpoint_dir': '3dunet', 'resume': None, 'validate_after_iters': 2, 'log_after_iters': 2, 'max_num_epochs': 1, 'max_num_iterations': 2, 'eval_score_higher_is_better': True}, 'optimizer': {'learning_rate': 0.0002, 'weight_decay': 1e-05}, 'loss': {'name': 'CrossEntropyLoss'}, 'eval_metric': {'name': 'MeanIoU', 'ignore_index': None}, 'lr_scheduler': {'name': 'MultiStepLR', 'milestones': [2, 3], 'gamma': 0.5}, 'loaders': {'dataset': 'StandardHDF5Dataset', 'batch_size': 1, 'num_workers': 4, 'raw_internal_path': 'raw', 'label_internal_path': 'label', 'weight_internal_path': None, 'train': {'file_paths': ['/net/fs01/work01/yasuda/pytorch-3dunet/tests/resources/train/'], 'slice_builder': {'name': 'SliceBuilder', 'patch_shape': [32, 64, 64], 'stride_shape': [32, 64, 64]}, 'transformer': {'raw': [{'name': 'Standardize'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'ToTensor', 'expand_dims': False, 'dtype': 'long'}], 'weight': [{'name': 'ToTensor', 'expand_dims': False}]}}, 'val': {'file_paths': ['/net/fs01/work01/yasuda/pytorch-3dunet/tests/resources/val/'], 'slice_builder': {'name': 'SliceBuilder', 'patch_shape': [32, 64, 64], 'stride_shape': [32, 64, 64]}, 'transformer': {'raw': [{'name': 'Standardize'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'ToTensor', 'expand_dims': False, 'dtype': 'long'}], 'weight': [{'name': 'ToTensor', 'expand_dims': False}]}}}, 'device': device(type='cuda', index=0)}
2022-05-17 01:01:52,324 [MainThread] INFO TrainingSetup - Seed the RNG for all devices with 0
2022-05-17 01:01:54,888 [MainThread] INFO UNet3DTrainer - Using 2 GPUs for training
2022-05-17 01:01:54,888 [MainThread] INFO UNet3DTrainer - Sending the model to 'cuda:0'
2022-05-17 01:02:06,688 [MainThread] INFO UNet3DTrainer - Number of learnable params 1021568
2022-05-17 01:02:06,688 [MainThread] INFO Dataset - Creating training and validation set loaders...
2022-05-17 01:02:09,119 [MainThread] INFO HDF5Dataset - Loading train set from: /net/fs01/work01/yasuda/pytorch-3dunet/tests/resources/train/sample_ovule.h5...
2022-05-17 01:02:09,511 [MainThread] INFO HDF5Dataset - Input stats: min=0, max=255, mean=60.068263875, std=76.11065799203715
2022-05-17 01:02:09,609 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [32, 64, 64], 'stride_shape': [32, 64, 64]}
2022-05-17 01:02:09,798 [MainThread] INFO HDF5Dataset - Number of patches: 343
2022-05-17 01:02:09,801 [MainThread] INFO HDF5Dataset - Loading val set from: /net/fs01/work01/yasuda/pytorch-3dunet/tests/resources/val/sample_ovule.h5...
2022-05-17 01:02:10,142 [MainThread] INFO HDF5Dataset - Input stats: min=0, max=255, mean=60.068263875, std=76.11065799203715
2022-05-17 01:02:10,239 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [32, 64, 64], 'stride_shape': [32, 64, 64]}
2022-05-17 01:02:10,240 [MainThread] INFO HDF5Dataset - Number of patches: 343
2022-05-17 01:02:10,241 [MainThread] INFO Dataset - Number of workers for train/val dataloader: 4
2022-05-17 01:02:10,241 [MainThread] INFO Dataset - 2 GPUs available. Using batch_size = 2 * 1
2022-05-17 01:02:10,241 [MainThread] INFO Dataset - Batch size for train/val loader: 2
2022-05-17 01:02:10,242 [MainThread] INFO UNet3DTrainer - DataParallel(
  (module): UNet3D(
    (encoders): ModuleList(
      (0): Encoder(
        (basic_module): DoubleConv(
          (SingleConv1): SingleConv(
            (groupnorm): GroupNorm(1, 3, eps=1e-05, affine=True)
            (conv): Conv3d(3, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
          (SingleConv2): SingleConv(
            (groupnorm): GroupNorm(4, 8, eps=1e-05, affine=True)
            (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
        )
      )
      (1): Encoder(
        (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (basic_module): DoubleConv(
          (SingleConv1): SingleConv(
            (groupnorm): GroupNorm(4, 16, eps=1e-05, affine=True)
            (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
          (SingleConv2): SingleConv(
            (groupnorm): GroupNorm(4, 16, eps=1e-05, affine=True)
            (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
        )
      )
      (2): Encoder(
        (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (basic_module): DoubleConv(
          (SingleConv1): SingleConv(
            (groupnorm): GroupNorm(4, 32, eps=1e-05, affine=True)
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
          (SingleConv2): SingleConv(
            (groupnorm): GroupNorm(4, 32, eps=1e-05, affine=True)
            (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
        )
      )
      (3): Encoder(
        (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (basic_module): DoubleConv(
          (SingleConv1): SingleConv(
            (groupnorm): GroupNorm(4, 64, eps=1e-05, affine=True)
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
          (SingleConv2): SingleConv(
            (groupnorm): GroupNorm(4, 64, eps=1e-05, affine=True)
            (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
        )
      )
    )
    (decoders): ModuleList(
      (0): Decoder(
        (upsampling): InterpolateUpsampling()
        (basic_module): DoubleConv(
          (SingleConv1): SingleConv(
            (groupnorm): GroupNorm(4, 192, eps=1e-05, affine=True)
            (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
          (SingleConv2): SingleConv(
            (groupnorm): GroupNorm(4, 64, eps=1e-05, affine=True)
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
        )
      )
      (1): Decoder(
        (upsampling): InterpolateUpsampling()
        (basic_module): DoubleConv(
          (SingleConv1): SingleConv(
            (groupnorm): GroupNorm(4, 96, eps=1e-05, affine=True)
            (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
          (SingleConv2): SingleConv(
            (groupnorm): GroupNorm(4, 32, eps=1e-05, affine=True)
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
        )
      )
      (2): Decoder(
        (upsampling): InterpolateUpsampling()
        (basic_module): DoubleConv(
          (SingleConv1): SingleConv(
            (groupnorm): GroupNorm(4, 48, eps=1e-05, affine=True)
            (conv): Conv3d(48, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
          (SingleConv2): SingleConv(
            (groupnorm): GroupNorm(4, 16, eps=1e-05, affine=True)
            (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (ReLU): ReLU(inplace=True)
          )
        )
      )
    )
    (final_conv): Conv3d(16, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))
    (final_activation): Softmax(dim=1)
  )
)
2022-05-17 01:02:10,243 [MainThread] INFO UNet3DTrainer - eval_score_higher_is_better: True
2022-05-17 01:02:10,391 [MainThread] INFO UNet3DTrainer - Training iteration [1/2]. Epoch [0/0]
Traceback (most recent call last):
  File "/home/people/yasuda/.conda/envs/3dunet/bin/train3dunet", line 10, in <module>
    sys.exit(main())
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/pytorch3dunet-1.3.3-py3.9.egg/pytorch3dunet/train.py", line 29, in main
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/pytorch3dunet-1.3.3-py3.9.egg/pytorch3dunet/unet3d/trainer.py", line 246, in fit
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/pytorch3dunet-1.3.3-py3.9.egg/pytorch3dunet/unet3d/trainer.py", line 273, in train
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/pytorch3dunet-1.3.3-py3.9.egg/pytorch3dunet/unet3d/trainer.py", line 402, in _forward_pass
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/pytorch3dunet-1.3.3-py3.9.egg/pytorch3dunet/unet3d/model.py", line 82, in forward
    x = encoder(x)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/pytorch3dunet-1.3.3-py3.9.egg/pytorch3dunet/unet3d/buildingblocks.py", line 237, in forward
    x = self.basic_module(x)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 268, in forward
    return F.group_norm(
  File "/home/people/yasuda/.conda/envs/3dunet/lib/python3.9/site-packages/torch/nn/functional.py", line 2360, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [3] and input of shape [1, 1, 32, 64, 64]

