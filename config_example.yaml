#UNet3D config file example

# Mandatory fields
checkpoint-dir: ./test_experiment # Checkpoint directory
in-channels: 1 # Number of input channels
out-channels: 2 # Number of output channels
init-channel-number: 16 # Initial number of feature maps in the encoder path which gets doubled on every stage (default: 64)
interpolate: interpolate # Use F.interpolate instead of ConvTranspose3d TODO action store
loss: ce # Which loss function to use. Possible values: ['bce', 'ce', 'wce', 'dice']
#  - bce: BinaryCrossEntropyLoss (binary classification only)
#  - ce: CrossEntropyLoss (multi-class classification)
#  - wce: WeightedCrossEntropyLoss (multi-class classification)
#  - dice: GeneralizedDiceLoss (multi-class classification)

# Data loader:  Mandatory fields
train-path: resources/random_label3D.h5 # Path to the train dataset
val-path: resources/random_label3D.h5 # Path to the validation dataset
train-patch: # Patch shape for used for validation. Order (z, x, y)
  - 32
  - 64
  - 64
train-stride: # Patch stride for used for training. Order (z, x, y)
  - 8
  - 16
  - 16
val-patch: # Patch shape for used for validation. Order (z, x, y)
  - 64
  - 128
  - 128
val-stride: # Patch stride for used for validation. Order (z, x, y)
  - 64
  - 128
  - 128

# Data loader:  Optional fields
raw-internal-path: raw # HDF5 file internal path to raw data
label-internal-path: label # HDF5 file internal path to labels
transformer: StandardTransformer # Data augmentation class

# Optional fields
layer-order: crg # Conv layer ordering, e.g. 'crg' -> Conv3D+ReLU+GroupNorm"
loss-weight: # A manual rescaling weight given to each class. Can be used with CrossEntropy or BCELoss. E.g. loss-weight: -0.3 -0.3 -0.4
ignore-index: # Specifies a target value that is ignored and does not contribute to the input gradient
curriculum: # Ise simple Curriculum Learning scheme if ignore_index is present TODO action store
final-sigmoid: False # If True apply element-wise nn.Sigmoid after the last layer otherwise apply nn.Softmax TODO action store
epochs: 500 # Max number of epochs
iters: 100000 # Max number of iterations
patience: 20 # Number of epochs with no loss improvement after which the training will be stopped
learning-rate: 0.0002 # Initial learning rate
weight-decay: 0.0001 # Weight decay (L2 penalty on weights)
validate-after-iters: 100 # How many iterations between validations
log-after-iters: 1 # How many iterations between tensorboard logging
resume: # Path to latest checkpoint (default: none); if provided the training will be resumed from that checkpoint